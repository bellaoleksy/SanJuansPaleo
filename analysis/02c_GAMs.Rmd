---
title: "02c_GAMs"
author: "Julia Pop"
date: "2025-09-22"
output: html_document
---

```{r setup, include=FALSE}
# code to troublesheet file path issues. 
# By default, knitr uses the folder containing the .Rmd file as
# the working directory. This code allows us to set the folder
# with our .rProj in it as the root. 

# find_root looks upwards from the .Rmd until it finds a file or
# folder that matches the criteria "folder with a .Rproj file in
# it."

knitr::opts_knit$set(root.dir = rprojroot::find_root(rprojroot::is_rstudio_project))
```

#Libraries -- add these here
```{r, echo = FALSE}
source("scripts/libraries.R")
source("scripts/GAM_functions.R")
```

**NOTE! use the short files for the gams unless interested in comparing pigment units (g TC vs g dry mass)**

## Pull in data
```{r}
all_lakes <- read.csv("output/all_lakes.csv") %>%
  select(-X)

UFM_short <- read.csv("output/UFM_short.csv") %>%
  select(-X)
LFM_short <- read.csv("output/LFM_short.csv") %>%
  select(-X)
TRK_short <- read.csv("output/TRK_short.csv") %>%
  select(-X)

LFM_short_extrap <- read.csv("output/LFM_short_extrap.csv") %>%
  select(-X)
```

### Adding a weight term
Added the weight term already in 00_data_input_and_manipulation.Rmd. Instead of calculating weights with interval = lag(), weight corresponds to the duration captured by each slice, as in Simpson 2018. Addresses HETERO - SKA - DA - STI - CITY.

**Questions:** 
- Gamma distributed vs. gaussian distributed data... 

### Exploring interpolated d15N LFM 
```{r}
### FAMILY:
# For our purposes, family = gaussian (normal) for isotopes 
# (they can have negative and positive values), and
# family = gamma for concentrations and rates
# in that case the mean of the response variable is restricted to [0,inf)... 

### K (sets the maximum # of bases for our spline): 

# Our dataset is very small: rule of thumb is to not let k approach n
    # how much data are we working with? 
    sum(!is.na(LFM_short$year_CE_plot)) # 18 observations. 
    
# try with and without corCAR1, and without weights then examine the residuals. 

# without weights
mod_d15N_LFM_nw <- gamm(d15N ~ s(year_CE_plot, k = 10), 
                     family = gaussian(link = "identity"), 
                     # does family correspond to the data or their residuals? 
                     # check with bella
                     data = LFM_short,
                     method = "REML")

# with weights, without car1
mod_d15N_LFM <- gamm(d15N ~ s(year_CE_plot, k = 10), 
                     family = gaussian(link = "identity"), 
                     data = LFM_short,
                     weights = weight, 
                     method = "REML")

# with weights, with car1
mod_d15N_LFM_CAR1 <- gamm(d15N ~ s(year_CE_plot, k = 10), 
                     family = gaussian(link = "identity"), 
                     data = LFM_short,
                     weights = weight, 
                     correlation = corCAR1(form = ~ year_CE_plot),
                     method = "REML")

resid_values_nw <- residuals(mod_d15N_LFM_nw$lme, type = "normalized") 
# no CAR(1), no weights
resid_values <- residuals(mod_d15N_LFM$lme, type = "normalized")  
# no CAR(1), with weights
resid_values_CAR1 <- residuals(mod_d15N_LFM_CAR1$lme, type = "normalized")   
# with CAR(1), with weights
all.equal(resid_values, resid_values_CAR1)  # Check if w and without car 1 are identical
# residuals are basically equal, so CAR(1) isn't doing much...

# check residuals
acf(resid_values_nw)
acf(resid_values)
acf(resid_values_CAR1)
# negative autocorrelation at lag 1, but CAR1 doesn't do anything about it...

# examine again using AIC:
AIC(mod_d15N_LFM_nw$lme) # without CAR(1) & without weights: -0.5703
# R is running the two models below this with ML instead of REML because of the weights. 
# to compare models, plot all with ML. then this AIC = -7.13, which is the best. so using no weight is ideal...
AIC(mod_d15N_LFM$lme)   # without CAR(1): -6.85481 
AIC(mod_d15N_LFM_CAR1$lme) # with CAR(1): -4.845512

summary(mod_d15N_LFM$gam)
summary(mod_d15N_LFM$lme)
summary(mod_d15N_LFM_nw$lme) # this one does use REML

gam.check(mod_d15N_LFM_nw$gam)
# best was without CAR1 and with the weights
# R is being annoying anyways and using ML instead of REML because of the weights... see if this matters in the future?
```


# LFM

## d15N
Use LFM_short_extrap to be able to plot all the data vs. time, but model only the interpolated dates. 
```{r}
### K (sets the maximum # of bases for our spline): 
# Our dataset is still small: rule of thumb is to not let k approach n
    # how much data are we working with? 
    sum(!is.na(LFM_short_extrap$year_plot_extrap)) # 43 observations. 

# Weights didn't help at all above. Model here without... 
    
# try with and without corCAR1, then examine the residuals. 
mod_d15N_LFM_ex <- gamm(d15N ~ s(year_CE_plot, k = 10), 
                     family = gaussian(link = "identity"), 
                     data = LFM_short_extrap,
                     method = "REML")

mod_d15N_LFM_CAR1_ex <- gamm(d15N ~ s(year_CE_plot, k = 10), 
                     family = gaussian(link = "identity"), 
                     data = LFM_short_extrap,
                     correlation = corCAR1(form = ~ year_CE_plot),
                     method = "REML")

summary(mod_d15N_LFM_CAR1_ex$lme) # no longer overriding reml! that's good.

resid_values_ex <- residuals(mod_d15N_LFM_ex$lme, type = "normalized")       # no CAR(1)
resid_values_CAR1_ex <- residuals(mod_d15N_LFM_CAR1_ex$lme, type = "normalized")   # with CAR(1)
all.equal(resid_values_ex, resid_values_CAR1_ex)  # Check if they are identical
# same! so CAR1 isn't helping -> drop

acf(resid_values_ex)
acf(resid_values_CAR1_ex)

# examine again using AIC:
AIC(mod_d15N_LFM_ex$lme)   # without CAR(1): -0.57
AIC(mod_d15N_LFM_CAR1$lme) # with CAR(1) from before: -4.84 (don't compare, was with ML)
AIC(mod_d15N_LFM_CAR1_ex$lme) # with CAR(1) now: 1.42
# lower AIC = better? better with CAR(1) still. 
# AIC=2kâˆ’2ln(L), where k = # parameters, L = likelihood.

    ### DECISION: move forward with mod_d15N_LFM_ex (no weights, no CAR1) ###

## summary object for use in document
d15NSumm_LFM_ex <- summary(mod_d15N_LFM_ex$gam)
d15NSumm_LFM_ex #Gives you the P values, degrees of freedom...

### Check diagnostics. You might need to adjust model
gam.check(mod_d15N_LFM_ex$gam)




### NOW PLOT! ###
N <- 300    # number of points at which to evaluate the splines

# Second, if you're only concerned about the response, include "response" in type of predict()???
d15NYear_LFM_ex <- with(LFM_short_extrap, 
                     data.frame(year_CE_plot = seq(min(year_CE_plot, na.rm=TRUE), max(year_CE_plot, na.rm=TRUE), length.out = 200)))

d15NYear_LFM_ex <- cbind(d15NYear_LFM_ex,
                      data.frame(predict(mod_d15N_LFM_ex$gam, d15NYear_LFM_ex,
                                         type="response", se.fit = TRUE)))

### this calculates on the link scale 
d15NYear_LFM_ex <- transform(d15NYear_LFM_ex, upper = fit + (2 * se.fit), lower = fit - (2 * se.fit))
d15NYear_LFM_ex$lake_ID <- 'LFM'

## Plot fitted trends
ggplot(d15NYear_LFM_ex, aes(x = year_CE_plot, y = fit)) +
  geom_ribbon(aes(ymin = (lower),
                  ymax = (upper), x = year_CE_plot),
              alpha = 0.2, inherit.aes = FALSE, fill = "black") +
  geom_point(data = LFM_short_extrap, mapping = aes(x = year_plot_extrap, y = d15N), inherit.aes = FALSE) +
  geom_line() 

# year_plot_extrap = year_CE_plot where dates are interpolated. Can use either for plotting points.

#First derivatives using gratia package instead of the 
#functions "helper_functions.R" (that Cale sent)
############
############
fd_inc = confint(fderiv(mod_d15N_LFM_ex))
fd_inc

#Add years for plotting
years <- with(LFM_short_extrap,
                     data.frame(year_CE_plot = seq(min(year_CE_plot, na.rm=TRUE), max(year_CE_plot, na.rm=TRUE), length.out = 200)))

fd_inc <- cbind(fd_inc,years)

#Plot the first derivatives
fd_inc %>%
  select(-term) %>%
  pivot_longer(lower:upper) %>%
  ggplot(aes(x=year_CE_plot,y=value,linetype=name))+
  geom_line()+
    scale_linetype_manual(values = c(
    "lower" = "dashed", #lower 95% confidence interval
    "upper" = "dashed", #upper 95% confidence interval
    "est"   = "solid"
  ))+
  theme(legend.position="none")+
  geom_hline(yintercept=0, color="red")
# Anywhere the confidence intervals DONT overlap zero is a statistically
# significant acceleration or deceleration in the trend


# When do they occur? You can check with an if/else type statement
fd_inc_timing <- fd_inc %>%
  mutate(change_type = case_when(lower < 0 & upper < 0 ~ "sig. dec.",
                                 lower > 0 & upper > 0 ~ "sig. inc.",
                                 TRUE ~ NA))
# View(fd_inc_timing)
#What you can see if a brief period of decline ~1900-1934, and again from 
#1960-present. This model, relative to Cale's seems more sensitive to that
#slight increase pre-1900. I think Cale's weighting is probably better

# For graphing, we want to join the predicted/fitted data with the 
# information with significant periods of change. Let's call it 'pred'

pred <- left_join(d15NYear_LFM_ex,
                  fd_inc_timing %>% 
                    select(year_CE_plot, change_type), #select only 2 columns since
                  #lower and upper have two different meanings in these 2 dataframes
                  by="year_CE_plot") 
  # mutate(fit = ifelse(change_type == "sig. dec.", fit, NA))

# Add a segment ID for plotting, so there there are multiple
# periods of change, ggplot doesn't connect the lines together
pred2 <- pred %>%
  mutate(seg_id = with(rle(ifelse(is.na(change_type), "none", change_type)),
                       rep(seq_along(values), lengths)))

# Keep only rows that are sig. inc or sig. dec
pred2 <- pred2 %>% filter(!is.na(change_type))

# Now make a pretty graph that shows the raw data, fitted trend,
# trend as well as periods of statistically significant increase/decrease!
ggplot(LFM_short_extrap) +
  geom_point(aes(year_plot_extrap, d15N)) +
  geom_ribbon(data = pred,
              aes(x = year_CE_plot, ymin = lower, ymax = upper),
              alpha = 0.2) +
  geom_line(data = pred,
            aes(x = year_CE_plot, y = fit),
            linewidth = 1,
            color = "black") +
  geom_line(data = pred2,
            aes(x = year_CE_plot, y = fit,
                color = change_type,
                group = seg_id),
            linewidth = 1) +
  scale_color_manual(values = c("sig. inc." = "#CC9933",
                                "sig. dec." = "#2f6cad"),
                     name ="Statistic") +
  scale_x_continuous(breaks=seq(1880,2025,by=25))+
  ylab(expression(paste(delta^{15}, "N (", "\u2030", ")"))) +
  xlab(expression(paste("Year (", italic("CE"), ")"))) +
  ggtitle("Lower Fourmile Lake")

ggsave("figures/LFM_d15N.png",
       dpi=600,
       height=5,
       width=8,
       units="in")
```




## d13C
Use LFM_short_extrap to be able to plot all the data vs. time, but model only the interpolated dates. 
```{r}
### K (sets the maximum # of bases for our spline): 
# Our dataset is still small: rule of thumb is to not let k approach n
    # how much data are we working with? 
    sum(!is.na(LFM_short_extrap$year_plot_extrap)) # 43 observations. 
    sum(!is.na(LFM_short_extrap$year_CE_plot)) # 18 observations.

# check later how weights, corCAR1 compare. 
    
# drop the "ex" for simplicity now that we know the dataset shouldn't affect the outcomes. 
mod_d13C_LFM <- gamm(d13C ~ s(year_CE_plot, k = 10), 
                     family = gaussian(link = "identity"), 
                     data = LFM_short_extrap,
                     method = "REML")

summary(mod_d13C_LFM$lme) # using REML - good.

resid_values_d13C_LFM <- residuals(mod_d13C_LFM$lme, type = "normalized")
acf(resid_values_d13C_LFM) # no lag, looks good without...

## summary object for use in document
d13CSumm_LFM <- summary(mod_d13C_LFM$gam)
d13CSumm_LFM #Gives you the P values, degrees of freedom...

### Check diagnostics. You might need to adjust model
gam.check(mod_d13C_LFM$gam)


### NOW PLOT! ###
N <- 300    # number of points at which to evaluate the splines

# Second, if you're only concerned about the response, include "response" in type of predict()???
d13CYear_LFM <- with(LFM_short_extrap, 
                     data.frame(year_CE_plot = seq(min(year_CE_plot, na.rm=TRUE), max(year_CE_plot, na.rm=TRUE), length.out = 200)))

d13CYear_LFM <- cbind(d13CYear_LFM,
                      data.frame(predict(mod_d13C_LFM$gam, d13CYear_LFM,
                                         type="response", se.fit = TRUE)))

### this calculates on the link scale 
d13CYear_LFM <- transform(d13CYear_LFM, upper = fit + (2 * se.fit), lower = fit - (2 * se.fit))
d13CYear_LFM$lake_ID <- 'LFM'

## Plot fitted trends
ggplot(d13CYear_LFM, aes(x = year_CE_plot, y = fit)) +
  geom_ribbon(aes(ymin = (lower),
                  ymax = (upper), x = year_CE_plot),
              alpha = 0.2, inherit.aes = FALSE, fill = "black") +
  geom_point(data = LFM_short_extrap, mapping = aes(x = year_plot_extrap, y = d13C), inherit.aes = FALSE) +
  geom_line() 

# year_plot_extrap = year_CE_plot where dates are interpolated. Can use either for plotting points.

#First derivatives using gratia package instead of the 
#functions "helper_functions.R" (that Cale sent)
############
############
fd_inc = confint(fderiv(mod_d13C_LFM))
fd_inc

#Add years for plotting
years <- with(LFM_short_extrap,
                     data.frame(year_CE_plot = seq(min(year_CE_plot, na.rm=TRUE), max(year_CE_plot, na.rm=TRUE), length.out = 200)))

fd_inc <- cbind(fd_inc,years)

#Plot the first derivatives
fd_inc %>%
  select(-term) %>%
  pivot_longer(lower:upper) %>%
  ggplot(aes(x=year_CE_plot,y=value,linetype=name))+
  geom_line()+
    scale_linetype_manual(values = c(
    "lower" = "dashed", #lower 95% confidence interval
    "upper" = "dashed", #upper 95% confidence interval
    "est"   = "solid"
  ))+
  theme(legend.position="none")+
  geom_hline(yintercept=0, color="red")
# Anywhere the confidence intervals DONT overlap zero is a statistically
# significant acceleration or deceleration in the trend


# When do they occur? You can check with an if/else type statement
fd_inc_timing <- fd_inc %>%
  mutate(change_type = case_when(lower < 0 & upper < 0 ~ "sig. dec.",
                                 lower > 0 & upper > 0 ~ "sig. inc.",
                                 TRUE ~ NA))
# View(fd_inc_timing)
#What you can see if a brief period of decline ~1900-1934, and again from 
#1960-present. This model, relative to Cale's seems more sensitive to that
#slight increase pre-1900. I think Cale's weighting is probably better

# For graphing, we want to join the predicted/fitted data with the 
# information with significant periods of change. Let's call it 'pred'

pred <- left_join(d13CYear_LFM,
                  fd_inc_timing %>% 
                    select(year_CE_plot, change_type), #select only 2 columns since
                  #lower and upper have two different meanings in these 2 dataframes
                  by="year_CE_plot") 
  # mutate(fit = ifelse(change_type == "sig. dec.", fit, NA))

# Add a segment ID for plotting, so there there are multiple
# periods of change, ggplot doesn't connect the lines together
pred2 <- pred %>%
  mutate(seg_id = with(rle(ifelse(is.na(change_type), "none", change_type)),
                       rep(seq_along(values), lengths)))

# Keep only rows that are sig. inc or sig. dec
pred2 <- pred2 %>% filter(!is.na(change_type))

# Now make a pretty graph that shows the raw data, fitted trend,
# trend as well as periods of statistically significant increase/decrease!
ggplot(LFM_short_extrap) +
  geom_point(aes(year_plot_extrap, d13C)) +
  geom_ribbon(data = pred,
              aes(x = year_CE_plot, ymin = lower, ymax = upper),
              alpha = 0.2) +
  geom_line(data = pred,
            aes(x = year_CE_plot, y = fit),
            linewidth = 1,
            color = "black") +
  geom_line(data = pred2,
            aes(x = year_CE_plot, y = fit,
                color = change_type,
                group = seg_id),
            linewidth = 1) +
  scale_color_manual(values = c("sig. inc." = "#CC9933",
                                "sig. dec." = "#2f6cad"),
                     name ="Statistic") +
  scale_x_continuous(breaks=seq(1880,2025,by=25))+
  ylab(expression(paste(delta^{13}, "C (", "\u2030", ")"))) +
  xlab(expression(paste("Year (", italic("CE"), ")"))) +
  ggtitle("Lower Fourmile Lake")

ggsave("figures/LFM_d13C.png",
       dpi=600,
       height=5,
       width=8,
       units="in")
```


## percent C
```{r}
### K (sets the maximum # of bases for our spline): 
# Our dataset is still small: rule of thumb is to not let k approach n
    # how much data are we working with? 
    sum(!is.na(LFM_short_extrap$year_plot_extrap)) # 43 observations. 
    sum(!is.na(LFM_short_extrap$year_CE_plot)) # 18 observations.

# check later how weights, corCAR1 compare. 
    
# drop the "ex" for simplicity now that we know the dataset shouldn't affect the outcomes. 
mod_perC_LFM <- gamm(percent.C ~ s(year_CE_plot, k = 10), 
                     family=Gamma(link="log"),  
                     data = LFM_short_extrap,
                     method = "REML")

summary(mod_perC_LFM$lme) # using REML - good.

resid_values_perC_LFM <- residuals(mod_perC_LFM$lme, type = "normalized")
acf(resid_values_perC_LFM) # slight negative lag at 2

## summary object for use in document
perCSumm_LFM <- summary(mod_perC_LFM$gam)
perCSumm_LFM #Gives you the P values, degrees of freedom...

### Check diagnostics. You might need to adjust model
gam.check(mod_perC_LFM$gam)


### now transform data: 
fam<-family(mod_perC_LFM)
fam
str(fam) 
ilink <- fam$linkinv
ilink 
Gamma()$linkinv 
ilink <- family(mod_perC_LFM)$linkinv 


### NOW PLOT! ###
N <- 300    # number of points at which to evaluate the splines

# Second, if you're only concerned about the response, include "response" in type of predict()???
perCYear_LFM <- with(LFM_short_extrap, 
                     data.frame(year_CE_plot = seq(min(year_CE_plot, na.rm=TRUE), max(year_CE_plot, na.rm=TRUE), length.out = 200)))

perCYear_LFM <- cbind(perCYear_LFM,
                      data.frame(predict(mod_perC_LFM$gam, perCYear_LFM,
                                         type="response", se.fit = TRUE)))

### this calculates on the link scale 
# perCYear_LFM <- transform(perCYear_LFM, fit = ilink(fit),
#                            upper = ilink(fit + (2 * se.fit)),
#                            lower = ilink(fit - (2 * se.fit))) ## and this creates confidence intervals for your model
perCYear_LFM <- transform(perCYear_LFM, fit = (fit),
                           upper = (fit + (2 * se.fit)),
                           lower = (fit - (2 * se.fit)))
                    
perCYear_LFM$lake_ID <- 'LFM'
     
    ## BROKEN - Plot fitted trends
    ggplot(perCYear_LFM, aes(x = year_CE_plot, y = fit)) +
    geom_ribbon(aes(ymin = (lower),
                  ymax = (upper), x = year_CE_plot),
                  alpha = 0.2, inherit.aes = FALSE, fill = "black") +
      geom_point(data = LFM_short_extrap, mapping = aes(x = year_plot_extrap, y = percent.C), inherit.aes = FALSE) +
      geom_line() 

# year_plot_extrap = year_CE_plot where dates are interpolated. Can use either for plotting points.

#First derivatives using gratia package instead of the 
#functions "helper_functions.R" (that Cale sent)
############
############

fd_inc = confint(fderiv(mod_perC_LFM))
fd_inc

#Add years for plotting
years <- with(LFM_short_extrap,
                     data.frame(year_CE_plot = seq(min(year_CE_plot, na.rm=TRUE), max(year_CE_plot, na.rm=TRUE), length.out = 200)))

fd_inc <- cbind(fd_inc,years)

#Plot the first derivatives
fd_inc %>%
  select(-term) %>%
  pivot_longer(lower:upper) %>%
  ggplot(aes(x=year_CE_plot,y=value,linetype=name))+
  geom_line()+
    scale_linetype_manual(values = c(
    "lower" = "dashed", #lower 95% confidence interval
    "upper" = "dashed", #upper 95% confidence interval
    "est"   = "solid"
  ))+
  theme(legend.position="none")+
  geom_hline(yintercept=0, color="red")
# Anywhere the confidence intervals DONT overlap zero is a statistically
# significant acceleration or deceleration in the trend


# When do they occur? You can check with an if/else type statement
fd_inc_timing <- fd_inc %>%
  mutate(change_type = case_when(lower < 0 & upper < 0 ~ "sig. dec.",
                                 lower > 0 & upper > 0 ~ "sig. inc.",
                                 TRUE ~ NA))
# View(fd_inc_timing)
#What you can see if a brief period of decline ~1900-1934, and again from 
#1960-present. This model, relative to Cale's seems more sensitive to that
#slight increase pre-1900. I think Cale's weighting is probably better

# For graphing, we want to join the predicted/fitted data with the 
# information with significant periods of change. Let's call it 'pred'

pred <- left_join(perCYear_LFM,
                  fd_inc_timing %>% 
                    select(year_CE_plot, change_type), #select only 2 columns since
                  #lower and upper have two different meanings in these 2 dataframes
                  by="year_CE_plot") 
  # mutate(fit = ifelse(change_type == "sig. dec.", fit, NA))

# Add a segment ID for plotting, so there there are multiple
# periods of change, ggplot doesn't connect the lines together
pred2 <- pred %>%
  mutate(seg_id = with(rle(ifelse(is.na(change_type), "none", change_type)),
                       rep(seq_along(values), lengths)))

# Keep only rows that are sig. inc or sig. dec
pred2 <- pred2 %>% filter(!is.na(change_type))

# Now make a pretty graph that shows the raw data, fitted trend,
# trend as well as periods of statistically significant increase/decrease!
ggplot(LFM_short_extrap) +
  geom_point(aes(year_plot_extrap, percent.C)) +
  geom_ribbon(data = pred,
              aes(x = year_CE_plot, ymin = lower, ymax = upper),
              alpha = 0.2) +
  geom_line(data = pred,
            aes(x = year_CE_plot, y = fit),
            linewidth = 1,
            color = "black") +
  geom_line(data = pred2,
            aes(x = year_CE_plot, y = fit,
                color = change_type,
                group = seg_id),
            linewidth = 1) +
  scale_color_manual(values = c("sig. inc." = "#CC9933",
                                "sig. dec." = "#2f6cad"),
                     name ="Statistic") +
  # scale_x_continuous(breaks=seq(1880,2025,by=25))+
  ylab("Total Carbon (%)") +
  xlab(expression(paste("Year (", italic("CE"), ")"))) +
  ggtitle("Lower Fourmile Lake")

ggsave("figures/LFM_perC.png",
       dpi=600,
       height=5,
       width=8,
       units="in")
```


## percent N
```{r}
### K (sets the maximum # of bases for our spline): 
# Our dataset is still small: rule of thumb is to not let k approach n
    # how much data are we working with? 
    sum(!is.na(LFM_short_extrap$year_plot_extrap)) # 43 observations. 
    sum(!is.na(LFM_short_extrap$year_CE_plot)) # 18 observations.

# check later how weights, corCAR1 compare. 
    
# drop the "ex" for simplicity now that we know the dataset shouldn't affect the outcomes. 
mod_perN_LFM <- gamm(percent.N ~ s(year_CE_plot, k = 10), 
                     family = gaussian(link = "identity"), 
                     data = LFM_short_extrap,
                     method = "REML")

summary(mod_d13C_LFM$lme) # using REML - good.

resid_values_perC_LFM <- residuals(mod_perC_LFM$lme, type = "normalized")
acf(resid_values_perC_LFM) # slight negative lag at 2

## summary object for use in document
perCSumm_LFM <- summary(mod_perC_LFM$gam)
perCSumm_LFM #Gives you the P values, degrees of freedom...

### Check diagnostics. You might need to adjust model
gam.check(mod_perC_LFM$gam)

### NOW PLOT! ###
N <- 300    # number of points at which to evaluate the splines

# Second, if you're only concerned about the response, include "response" in type of predict()???
perCYear_LFM <- with(LFM_short_extrap, 
                     data.frame(year_CE_plot = seq(min(year_CE_plot, na.rm=TRUE), max(year_CE_plot, na.rm=TRUE), length.out = 200)))

perCYear_LFM <- cbind(perCYear_LFM,
                      data.frame(predict(mod_perC_LFM$gam, perCYear_LFM,
                                         type="response", se.fit = TRUE)))

### this calculates on the link scale 
perCYear_LFM <- transform(perCYear_LFM, upper = fit + (2 * se.fit), lower = fit - (2 * se.fit))
perCYear_LFM$lake_ID <- 'LFM'

## Plot fitted trends
ggplot(perCYear_LFM, aes(x = year_CE_plot, y = fit)) +
  geom_ribbon(aes(ymin = (lower),
                  ymax = (upper), x = year_CE_plot),
              alpha = 0.2, inherit.aes = FALSE, fill = "black") +
  geom_point(data = LFM_short_extrap, mapping = aes(x = year_plot_extrap, y = percent.C), inherit.aes = FALSE) +
  geom_line() 

# year_plot_extrap = year_CE_plot where dates are interpolated. Can use either for plotting points.

#First derivatives using gratia package instead of the 
#functions "helper_functions.R" (that Cale sent)
############
############
fd_inc = confint(fderiv(mod_perC_LFM))
fd_inc

#Add years for plotting
years <- with(LFM_short_extrap,
                     data.frame(year_CE_plot = seq(min(year_CE_plot, na.rm=TRUE), max(year_CE_plot, na.rm=TRUE), length.out = 200)))

fd_inc <- cbind(fd_inc,years)

#Plot the first derivatives
fd_inc %>%
  select(-term) %>%
  pivot_longer(lower:upper) %>%
  ggplot(aes(x=year_CE_plot,y=value,linetype=name))+
  geom_line()+
    scale_linetype_manual(values = c(
    "lower" = "dashed", #lower 95% confidence interval
    "upper" = "dashed", #upper 95% confidence interval
    "est"   = "solid"
  ))+
  theme(legend.position="none")+
  geom_hline(yintercept=0, color="red")
# Anywhere the confidence intervals DONT overlap zero is a statistically
# significant acceleration or deceleration in the trend


# When do they occur? You can check with an if/else type statement
fd_inc_timing <- fd_inc %>%
  mutate(change_type = case_when(lower < 0 & upper < 0 ~ "sig. dec.",
                                 lower > 0 & upper > 0 ~ "sig. inc.",
                                 TRUE ~ NA))
View(fd_inc_timing)
#What you can see if a brief period of decline ~1900-1934, and again from 
#1960-present. This model, relative to Cale's seems more sensitive to that
#slight increase pre-1900. I think Cale's weighting is probably better

# For graphing, we want to join the predicted/fitted data with the 
# information with significant periods of change. Let's call it 'pred'

pred <- left_join(perCYear_LFM,
                  fd_inc_timing %>% 
                    select(year_CE_plot, change_type), #select only 2 columns since
                  #lower and upper have two different meanings in these 2 dataframes
                  by="year_CE_plot") 
  # mutate(fit = ifelse(change_type == "sig. dec.", fit, NA))

# Add a segment ID for plotting, so there there are multiple
# periods of change, ggplot doesn't connect the lines together
pred2 <- pred %>%
  mutate(seg_id = with(rle(ifelse(is.na(change_type), "none", change_type)),
                       rep(seq_along(values), lengths)))

# Keep only rows that are sig. inc or sig. dec
pred2 <- pred2 %>% filter(!is.na(change_type))

# Now make a pretty graph that shows the raw data, fitted trend,
# trend as well as periods of statistically significant increase/decrease!
ggplot(LFM_short_extrap) +
  geom_point(aes(year_plot_extrap, percent.C)) +
  geom_ribbon(data = pred,
              aes(x = year_CE_plot, ymin = lower, ymax = upper),
              alpha = 0.2) +
  geom_line(data = pred,
            aes(x = year_CE_plot, y = fit),
            linewidth = 1,
            color = "black") +
  geom_line(data = pred2,
            aes(x = year_CE_plot, y = fit,
                color = change_type,
                group = seg_id),
            linewidth = 1) +
  scale_color_manual(values = c("sig. inc." = "#CC9933",
                                "sig. dec." = "#2f6cad"),
                     name ="Statistic") +
  scale_x_continuous(breaks=seq(1880,2025,by=25))+
  ylab("Total Carbon (%)") +
  xlab(expression(paste("Year (", italic("CE"), ")"))) +
  ggtitle("Lower Fourmile Lake")

ggsave("figures/LFM_perC.png",
       dpi=600,
       height=5,
       width=8,
       units="in")
```

# Example Code
### GAMs- Bella's way
```{r}
### family=Gamma(link="log") for gamma distributed errors
### family = gaussian(link = "identity") for normal data with negative values
mod_d15N_LFM <- gamm(d15N ~ s(year_CE, k = 10),
                     family = gaussian(link = "identity"), 
                     data = LFM_short,
                     correlation = corCAR1(form = ~ year_CE), method = "REML")

## summary object for use in document
d15NSumm_LFM <- summary(mod_d15N_LFM$gam)
d15NSumm_LFM #Gives you the P values, degrees of freedom...
print.summary.gam(d15NSumm_LFM)

### Check diagnostics. You might need to adjust model
gam.check(mod_d15N_LFM$gam)

N <- 300    # number of points at which to evaluate the splines

### Second, if you're only concerned about the response, include "response" in type of predict()
d15NYear_LFM <- with(LFM_short,
                     data.frame(year_CE = seq(min(year_CE, na.rm=TRUE), max(year_CE, na.rm=TRUE), length.out = 200)))
d15NYear_LFM <- cbind(d15NYear_LFM,
                      data.frame(predict(mod_d15N_LFM$gam, d15NYear_LFM,
                                         type="response", se.fit = TRUE)))

### this calculates on the link scale (i.e., log)
d15NYear_LFM <- transform(d15NYear_LFM, upper = fit + (2 * se.fit), lower = fit - (2 * se.fit))
d15NYear_LFM$lake_ID <- 'LFM'

## Plot fitted trends
del15N_fitted_S <- ggplot(d15NYear_LFM, aes(x = year_CE, y = fit)) +
  geom_ribbon(aes(ymin = (lower),
                  ymax = (upper), x = year_CE),
              alpha = 0.2, inherit.aes = FALSE, fill = "black") +
  geom_point(data = LFM_short, mapping = aes(x = year_CE, y = d15N), inherit.aes = FALSE) +
  geom_line() 
del15N_fitted_S

#Note that this quick & dirty way basically achieves something similar but the 
#band around the trend looks different. This way is fine if you are just trying 
#to make some quick plots for GREEBS
LFM_short %>%
  ggplot(aes(x=year_CE,y=d15N))+
  geom_point()+
  geom_smooth(method="gam")


############
############
#First derivatives using gratia packageinstead of the 
#functions "helper_functions.R" (that Cale sent)
############
############
fd_inc = confint(fderiv(mod_d15N_LFM))
fd_inc

#Add years for plotting
years <- with(LFM_short,
                     data.frame(year_CE = seq(min(year_CE, na.rm=TRUE), max(year_CE, na.rm=TRUE), length.out = 200)))

fd_inc <- cbind(fd_inc,years)

#Plot the first derivatives
fd_inc %>%
  select(-term) %>%
  pivot_longer(lower:upper) %>%
  ggplot(aes(x=year_CE,y=value,linetype=name))+
  geom_line()+
    scale_linetype_manual(values = c(
    "lower" = "dashed", #lower 95% confidence interval
    "upper" = "dashed", #upper 95% confidence interval
    "est"   = "solid"
  ))+
  theme(legend.position="none")+
  geom_hline(yintercept=0, color="red")
# Anywhere the confidence intervals DONT overlap zero is a statistically
# significant acceleration or deceleration in the trend


# When do they occur? You can check with an if/else type statement
fd_inc_timing <- fd_inc %>%
  mutate(change_type = case_when(lower < 0 & upper < 0 ~ "sig. dec.",
                                 lower > 0 & upper > 0 ~ "sig. inc.",
                                 TRUE ~ NA))
View(fd_inc_timing)
#What you can see if a brief period of decline ~1900-1934, and again from 
#1960-present. This model, relative to Cale's seems more sensitive to that
#slight increase pre-1900. I think Cale's weighting is probably better


# For graphing, we want to join the predicted/fitted data with the 
# information with significant periods of change. Let's call it 'pred'

pred <- left_join(d15NYear_LFM,
                  fd_inc_timing %>% 
                    select(year_CE, change_type), #select only 2 columns since
                  #lower and upper have two different meanings in these 2 dataframes
                  by="year_CE") 
  # mutate(fit = ifelse(change_type == "sig. dec.", fit, NA))

# Add a segment ID for plotting, so there there are multiple
# periods of change, ggplot doesn't connect the lines together
pred2 <- pred %>%
  mutate(seg_id = with(rle(ifelse(is.na(change_type), "none", change_type)),
                       rep(seq_along(values), lengths)))

# Keep only rows that are sig. inc or sig. dec
pred2 <- pred2 %>% filter(!is.na(change_type))

# Now make a pretty graph that shows the raw data, fitted trend,
# trend as well as periods of statistically significant increase/decrease!
ggplot(LFM_short) +
  geom_point(aes(year_CE, d15N)) +
  geom_ribbon(data = pred,
              aes(x = year_CE, ymin = lower, ymax = upper),
              alpha = 0.2) +
  geom_line(data = pred,
            aes(x = year_CE, y = fit),
            linewidth = 1,
            color = "black") +
  geom_line(data = pred2,
            aes(x = year_CE, y = fit,
                color = change_type,
                group = seg_id),
            linewidth = 1) +
  scale_color_manual(values = c("sig. inc." = "#CC9933",
                                "sig. dec." = "#2f6cad"),
                     name ="Statistic") +
  scale_x_continuous(breaks=seq(1880,2025,by=25))+
  ylab(expression(paste(delta^{15}, "N (", "\u2030", ")"))) +
  xlab(expression(paste("Year (", italic("CE"), ")"))) +
  ggtitle("Lower Fourmile Lake")

ggsave("figures/LFM_d15N.png",
       dpi=600,
       height=5,
       width=5,
       units="in")


# FOR WHAT IT'S WORTH... 
# Here is old code I have modified from Gavin Simpson, basically identical to what Cale provided.
# https://www.fromthebottomoftheheap.net/2014/05/15/identifying-periods-of-change-with-gams/
# Make the same plot as above but in base R. You may prefer ggplot2 (I do, these)
Term <- "year_CE"
m2.d <- Deriv(mod_d15N_LFM)
m2.dci <- confint(m2.d, term = "year_CE")
m2.dsig <- signifD(d15NYear_LFM$fit,
                   d = m2.d[[Term]]$deriv,
                   m2.dci[[Term]]$upper,
                   m2.dci[[Term]]$lower)



ylim <- with(d15NYear_LFM, range(upper, lower, fit))
ylab <- expression(paste(delta^{15}, "N (â€°)"))

plot(fit ~ year_CE, data = d15NYear_LFM, type = "n", ylab = ylab, ylim = ylim)
lines(fit ~ year_CE, data = d15NYear_LFM)
lines(upper ~ year_CE, data = d15NYear_LFM, lty = "dashed")
lines(lower ~ year_CE, data = d15NYear_LFM, lty = "dashed")
lines(unlist(m2.dsig$incr) ~ year_CE, data = d15NYear_LFM, col = "blue", lwd = 3)
lines(unlist(m2.dsig$decr) ~ year_CE, data = d15NYear_LFM, col = "red", lwd = 3)


decr<-data.frame(unlist(m2.dsig$decr), d15NYear_LFM$age_sky) %>%
  rename(value=unlist.m2.dsig.decr.,
         age_sky=del15NYear_S.age_sky)
```
### Gams - Cale's way
```{r}

m.beta <- gam(d15N ~s(year_CE, k = 10), # this is simply the trend by date
              data = LFM_short, ## the data used
              family = gaussian(link = "identity"),  # use Gaussian for roughly normal data
                  ## Use Gamma for concentration data
              bs='tp',## spline - thin plate is ok for simple models like this 
              method="REML", ## method - always use REML for gam
              weights = weight) ## here we add the weight term

# now check if the gam is good
summary(m.beta)
plot(m.beta)
gam.check(m.beta)

### now that you have a good model, you need to predict new data over your original data
### before we predict, we need to transform the data to deal
## with the Gamma family
fam<-family(m.beta)
fam
str(fam) 
ilink <- fam$linkinv
ilink 
Gamma()$linkinv 
ilink <- family(m.beta)$linkinv 

### now we predict 
pred <- with(LFM_short, data.frame(year_CE = seq(min(year_CE,na.rm=TRUE), max(year_CE,na.rm=TRUE), ## this is making fake dates to model through
                                        length.out = 200))) ### 200-300 are usually good numbers of data points
pred <- cbind(pred,
              data.frame(predict(m.beta, pred, se.fit = TRUE))) # add the prediction to your data
## now we use the ilink to account for the transformation
pred <- transform(pred, fit = ilink(fit), 
                  upper = ilink(fit + (2 * se.fit)),
                  lower = ilink(fit - (2 * se.fit))) ## and this creates confidence intervals for your model



## Derive from your model!
dt.Der<-Deriv(m.beta) ## derive
plot(dt.Der, sizer = TRUE)
Term<-"year_CE" 
dt.dci<-confint(dt.Der, term = Term) ## make confidence intervals
dt.dsig<-signifD(pred$fit, d = dt.Der[[Term]]$deriv,
                 dt.dci[[Term]]$upper, dt.dci[[Term]]$lower) ### show significance

### now we make a simple plot
p.beta <- 
  ggplot(LFM_short)+
  geom_point(aes(year_CE, d15N))+
  geom_ribbon(data=pred, aes(ymin=lower, ymax=upper, x=year_CE), alpha=0.2)+
  geom_line(data=pred, aes(year_CE, fit), linewidth=1, color="black")+
  geom_line(data=pred, aes(year_CE, dt.dsig$decr), color="#CC9933", lwd=2)+ ## this highlights what areas have significant changes
  geom_line(data=pred, aes(year_CE, dt.dsig$incr), color="#CC9933", lwd=2)+
  scale_x_continuous(breaks=seq(1880,2025,by=25))+
  ylab('d15N')+
  xlab('Year')+
  theme_bw()
p.beta



```

### Compare pheo model fits - edited
```{r}

hist(LFM_short_extrap$phaeo_b_nmol_gTC)
hist(log(LFM_short_extrap$phaeo_b_nmol_gTC))


m.pheob.normal <- gam(phaeo_b_nmol_gTC ~s(year_plot_extrap, k = 10), # this is simply the trend by date
              data = LFM_short_extrap, ## the data used
              family = gaussian(link = "identity"),  
              bs='tp',## spline - thin plate is ok for simple models like this 
              method="REML"
      #        correlation = corCAR1(form = ~ year_plot_extrap),
              ) ## method - always use REML for gam
              ## here we add the weight term

m.pheob.gamma <- gam(phaeo_b_nmol_gTC ~s(year_plot_extrap, k = 10), # this is simply the trend by date
              data = LFM_short_extrap, ## the data used
              family=Gamma(link="log"),  
              bs='tp',## spline - thin plate is ok for simple models like this 
       #       correlation = corCAR1(form = ~ year_plot_extrap),
              method="REML") ## method - always use REML for gam
              ## weights = weight) ## here we add the weight term

par(mfrow = c(2, 2))
gam.check(m.pheob.normal)
par(mfrow = c(2, 2))
gam.check(m.pheob.gamma)

summary(m.pheob.normal)
summary(m.pheob.gamma) 

AIC(m.pheob.normal, m.pheob.gamma) # gamma is lower (but very similar?)

par(mfrow = c(1, 2))
plot(fitted(m.pheob.normal), resid(m.pheob.normal), main = "Gaussian")
abline(h = 0, col = "red")
plot(fitted(m.pheob.gamma), resid(m.pheob.gamma), main = "Gamma(log)")
abline(h = 0, col = "red")

# The deviance explained in the gamma model is higher but the AIC is very similar.
# Let's look at the model fits and decide? 
```

#### Pheo b normal/gaussian family
```{r}
### now that you have a good model, you need to predict new data over your original data
### before we predict, we need to transform the data to deal
## with the Gamma family
fam<-family(m.pheob.normal)
fam
str(fam) 
ilink <- fam$linkinv
ilink 
Gamma()$linkinv # <- JP: why are we doing a gamma transformation here for the normal dist?
ilink <- family(m.pheob.normal)$linkinv 

### now we predict 
pred <- with(LFM_short_extrap, data.frame(year_plot_extrap = seq(min(year_plot_extrap,na.rm=TRUE), max(year_plot_extrap,na.rm=TRUE), ## this is making fake dates to model through
                                        length.out = 200))) ### 200-300 are usually good numbers of data points
pred <- cbind(pred,
              data.frame(predict(m.pheob.normal, pred, se.fit = TRUE))) # add the prediction to your data
## now we use the ilink to account for the transformation
pred <- transform(pred, fit = ilink(fit), 
                  upper = ilink(fit + (2 * se.fit)),
                  lower = ilink(fit - (2 * se.fit))) ## and this creates confidence intervals for your model

## Derive from your model!
dt.Der<-Deriv(m.pheob.normal) ## derive
plot(dt.Der, sizer = TRUE)
Term<-"year_plot_extrap" 
dt.dci<-confint(dt.Der, term = Term) ## make confidence intervals
dt.dsig<-signifD(pred$fit, d = dt.Der[[Term]]$deriv,
                 dt.dci[[Term]]$upper, dt.dci[[Term]]$lower) ### show significance

### now we make a simple plot
  ggplot(LFM_short_extrap)+
  geom_point(aes(year_plot_extrap, phaeo_b_nmol_gTC))+
  geom_ribbon(data=pred, aes(ymin=lower, ymax=upper, x=year_plot_extrap), alpha=0.2)+
  geom_line(data=pred, aes(year_plot_extrap, fit), linewidth=1, color="black")+
  geom_line(data=pred, aes(year_plot_extrap, dt.dsig$decr), color="#CC9933", lwd=2)+ ## this highlights what areas have significant changes
  geom_line(data=pred, aes(year_plot_extrap, dt.dsig$incr), color="#CC9933", lwd=2)+
  scale_x_continuous(breaks=seq(1880,2025,by=25))+
  ylab('pheo b - gaussian family')+
  xlab('Year')+
  theme_bw()
```


#### Pheo b gamma family
```{r}
### now that you have a good model, you need to predict new data over your original data
### before we predict, we need to transform the data to deal
## with the Gamma family
fam<-family(m.pheob.gamma)
fam
str(fam) 
ilink <- fam$linkinv
ilink 
Gamma()$linkinv 
ilink <- family(m.pheob.gamma)$linkinv 

### now we predict 
pred <- with(LFM_short_extrap, data.frame(year_plot_extrap = seq(min(1850,na.rm=TRUE), max(year_plot_extrap,na.rm=TRUE), ## this is making fake dates to model through
                                        length.out = 200))) ### 200-300 are usually good numbers of data points
pred <- cbind(pred,
              data.frame(predict(m.pheob.gamma, pred, se.fit = TRUE))) # add the prediction to your data
## now we use the ilink to account for the transformation
pred <- transform(pred, fit = ilink(fit), 
                  upper = ilink(fit + (2 * se.fit)),
                  lower = ilink(fit - (2 * se.fit))) ## and this creates confidence intervals for your model



## Derive from your model!
dt.Der<-Deriv(m.pheob.gamma) ## derive
plot(dt.Der, sizer = TRUE)
Term<-"year_plot_extrap" 
dt.dci<-confint(dt.Der, term = Term) ## make confidence intervals
dt.dsig<-signifD(pred$fit, d = dt.Der[[Term]]$deriv,
                 dt.dci[[Term]]$upper, dt.dci[[Term]]$lower) ### show significance

### now we make a simple plot
  ggplot(LFM_short_extrap)+
  geom_point(aes(year_plot_extrap, phaeo_b_nmol_gTC))+
  geom_ribbon(data=pred, aes(ymin=lower, ymax=upper, x=year_plot_extrap), alpha=0.2)+
  geom_line(data=pred, aes(year_plot_extrap, fit), linewidth=1, color="black")+
  geom_line(data=pred, aes(year_plot_extrap, dt.dsig$decr), color="#CC9933", lwd=2)+ ## this highlights what areas have significant changes
  geom_line(data=pred, aes(year_plot_extrap, dt.dsig$incr), color="#CC9933", lwd=2)+
  # scale_x_continuous(breaks=seq(1880,2025,by=25))+
  ylab('pheo b - gaussian family')+
  xlab('Year')+
  theme_bw()

# Gaussian family seems to fit the data a bit better to me.
# First derivatives don't show evidence for an acceleration in the trend
```